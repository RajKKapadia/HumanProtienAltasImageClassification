{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nfrom PIL import Image\n\n# Let's import packages\nfrom keras.layers import Input, Add, Dense, Activation, BatchNormalization\nfrom keras.layers import Flatten, Conv2D, MaxPooling2D, Dropout\n\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping\n\nfrom keras.models import Model",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_csv = pd.read_csv(\"../input/train.csv\")\n\nTRAIN_PATH = \"../input/train/\"\nTEST_PATH = \"../input/test/\"\ncolours = [\"red\", \"green\", \"blue\", \"yellow\"]\nids = train_csv[\"Id\"]\ntargets = train_csv[\"Target\"]\nbatches = [1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n           1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n           1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n           1072]\nnumb_labels = 28",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "84487316b824f89cce23325361c5447e687aa1c5"
      },
      "cell_type": "code",
      "source": "# Input\ngreen = Input(shape=(512, 512, 1))\n\nbn0 = BatchNormalization(scale=True)(green)\n\n# Initial Stage\nconv1 = Conv2D(32, kernel_size=(7,7), padding='same', activation='relu', kernel_initializer='uniform')(bn0)\nbn1 = BatchNormalization(scale=True)(conv1)\nmax_pool1 = MaxPooling2D(pool_size=(2,2))(bn1)\n\n# First\nconv2 = Conv2D(32, kernel_size=(5,5), padding='same', activation='relu', kernel_initializer='uniform')(max_pool1)\nbn2 = BatchNormalization(scale=True)(conv2)\n\nconv3 = Conv2D(32, kernel_size=(3,3), padding='same', kernel_initializer='uniform')(bn2)\nbn3 = BatchNormalization(scale=True)(conv3)\n\n# First Residual\nres_conv1 = Conv2D(32, kernel_size=(3,3), padding='same', kernel_initializer='uniform')(max_pool1)\nres_bn1 = BatchNormalization(scale=True)(res_conv1)\n\n# First Add\nadd1 = Add()([res_bn1, bn3])\n\n# First Acvtivation & MaxPooling\nact1 = Activation('relu')(add1)\nmax_pool2 = MaxPooling2D(pool_size=(2,2))(act1)\n\n# Second\nconv4 = Conv2D(64, kernel_size=(5,5), padding='same', activation='relu', kernel_initializer='uniform')(max_pool2)\nbn4 = BatchNormalization(scale=True)(conv4)\n\nconv5 = Conv2D(64, kernel_size=(3,3), padding='same', kernel_initializer='uniform')(bn4)\nbn5 = BatchNormalization(scale=True)(conv5)\n\n# Second Residual\nres_conv2 = Conv2D(64, kernel_size=(3,3), padding='same', kernel_initializer='uniform')(max_pool2)\nres_bn2 = BatchNormalization(scale=True)(res_conv2)\n\n# Second Add\nadd2 = Add()([res_bn2, bn5])\n\n# Second Acvtivation & MaxPooling\nact2 = Activation('relu')(add2)\nmax_pool3 = MaxPooling2D(pool_size=(2,2))(act2)\n\n# Third\nconv6 = Conv2D(128, kernel_size=(5,5), padding='same', activation='relu', kernel_initializer='uniform')(max_pool3)\nbn6 = BatchNormalization(scale=True)(conv6)\n\nconv7 = Conv2D(128, kernel_size=(3,3), padding='same', kernel_initializer='uniform')(bn6)\nbn7 = BatchNormalization(scale=True)(conv7)\n\n# Third Residual\nres_conv3 = Conv2D(128, kernel_size=(3,3), padding='same', kernel_initializer='uniform')(max_pool3)\nres_bn3 = BatchNormalization(scale=True)(res_conv3)\n\n# Third Add\nadd3 = Add()([res_bn3, bn7])\n\n# Third Acvtivation & MaxPooling\nact3 = Activation('relu')(add3)\nmax_pool4 = MaxPooling2D(pool_size=(2,2))(act3)\n\n# Four\nconv8 = Conv2D(256, kernel_size=(5,5), padding='same', activation='relu', kernel_initializer='uniform')(max_pool4)\nbn8 = BatchNormalization(scale=True)(conv8)\n\nconv9 = Conv2D(256, kernel_size=(3,3), padding='same', kernel_initializer='uniform')(bn8)\nbn9 = BatchNormalization(scale=True)(conv9)\n\n# Four Residual\nres_conv4 = Conv2D(256, kernel_size=(3,3), padding='same', kernel_initializer='uniform')(max_pool4)\nres_bn4 = BatchNormalization(scale=True)(res_conv4)\n\n# Four Add\nadd4 = Add()([res_bn4, bn9])\n\n# Four Acvtivation & MaxPooling\nact4 = Activation('relu')(add4)\nmax_pool5 = MaxPooling2D(pool_size=(2,2))(act4)\n\n# Five\nconv10 = Conv2D(256, kernel_size=(5,5), padding='same', activation='relu', kernel_initializer='uniform')(max_pool5)\nbn10 = BatchNormalization(scale=True)(conv10)\n\nconv11 = Conv2D(256, kernel_size=(3,3), padding='same', kernel_initializer='uniform')(bn10)\nbn11 = BatchNormalization(scale=True)(conv11)\n\n# Five Residual\nres_conv5 = Conv2D(256, kernel_size=(3,3), padding='same', kernel_initializer='uniform')(max_pool5)\nres_bn5 = BatchNormalization(scale=True)(res_conv5)\n\n# Five Add\nadd5 = Add()([res_bn5, bn11])\n\n# Five Acvtivation & MaxPooling\nact5 = Activation('relu')(add5)\nmax_pool6 = MaxPooling2D(pool_size=(2,2))(act5)\n\n# Six\nconv12 = Conv2D(256, kernel_size=(5,5), padding='same', activation='relu', kernel_initializer='uniform')(max_pool6)\nbn12 = BatchNormalization(scale=True)(conv12)\n\nconv13 = Conv2D(256, kernel_size=(3,3), padding='same', kernel_initializer='uniform')(bn12)\nbn13 = BatchNormalization(scale=True)(conv13)\n\n# Six Residual\nres_conv6 = Conv2D(256, kernel_size=(3,3), padding='same', kernel_initializer='uniform')(max_pool6)\nres_bn6 = BatchNormalization(scale=True)(res_conv6)\n\n# Six Add\nadd6 = Add()([res_bn6, bn13])\n\n# Six Acvtivation & MaxPooling\nact6 = Activation('relu')(add6)\nmax_pool7 = MaxPooling2D(pool_size=(2,2))(act6)\n\nflatten = Flatten()(max_pool7)\n\ndense1 = Dense(512, activation='relu')(flatten)\ndo = Dropout(0.25)(dense1)\n\ndense2 = Dense(28, activation='sigmoid')(do)\n\nmodel = Model(inputs=[green], outputs=[dense2])\n\n# Parameters for training\nadam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n\nmodel.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n\nmodel.summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8fd99a7166ad4802e4e6f30a7f88c039c457c8e8"
      },
      "cell_type": "code",
      "source": "batch_id = 1\n\n# Model fitting parameters\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001, verbose=1)\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n\nindex = 0\n\nfor batch in batches:\n    print(\"Processing batch number \" + str(batch_id))\n    # Create empty images and labels\n    images = np.zeros((batch, 512, 512, 1))\n    labels = np.zeros((batch, numb_labels))\n    \n    for i in range(batch):\n        green = np.asarray(Image.open(TRAIN_PATH+ids[index]+\"_\"+colours[1]+\".png\"))\n        index += 1\n        images[i] = green.reshape(512, 512, 1)/255\n        \n        target = targets[i].split(\" \")\n        \n        for value in target:\n            labels[i, int(value)] = 1\n            \n    print(\"Fitting the data to the model.\")\n    model.fit(images, labels, batch_size=32, epochs=10, verbose=1, validation_split=0.1, callbacks=[reduce_lr, early_stopping])\n    batch_id += 1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b4dc0b761f247cf427e31b9ce026543f6768d097"
      },
      "cell_type": "code",
      "source": "test_csv = pd.read_csv(\"../input/sample_submission.csv\")\nids_test = test_csv[\"Id\"]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5d34ef9bbc954341c6885b1afab9d1a5729d764f"
      },
      "cell_type": "code",
      "source": "y_pred = np.zeros((len(ids_test), numb_labels))\nimage_test = np.zeros((1, 512, 512, 1))\n\nfor i in range(len(ids_test)):\n    \n    green = np.asarray(Image.open(TEST_PATH+ids_test[i]+\"_\"+colours[1]+\".png\"))\n    image_test[0] = green.reshape(512, 512, 1)/255\n    \n    print(\"Sample number \" + str(i))\n    y_pred[i] = model.predict(image_test, verbose=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a04b1d255540f9055a07fe23450c342679ae917f"
      },
      "cell_type": "code",
      "source": "y_pred[:, 0] = (y_pred[:, 0] > 0.5).astype(int)\ny_pred[:, 1] = (y_pred[:, 1] > 0.4).astype(int)\ny_pred[:, 2] = (y_pred[:, 2] > 0.4).astype(int)\ny_pred[:, 3] = (y_pred[:, 3] > 0.4).astype(int)\ny_pred[:, 4] = (y_pred[:, 4] > 0.4).astype(int)\ny_pred[:, 5] = (y_pred[:, 5] > 0.4).astype(int)\ny_pred[:, 6] = (y_pred[:, 6] > 0.4).astype(int)\ny_pred[:, 7] = (y_pred[:, 7] > 0.4).astype(int)\ny_pred[:, 8] = (y_pred[:, 8] > 0.2).astype(int)\ny_pred[:, 9] = (y_pred[:, 9] > 0.2).astype(int)\ny_pred[:, 10] = (y_pred[:, 10] > 0.2).astype(int)\ny_pred[:, 11] = (y_pred[:, 11] > 0.4).astype(int)\ny_pred[:, 12] = (y_pred[:, 12] > 0.4).astype(int)\ny_pred[:, 13] = (y_pred[:, 13] > 0.4).astype(int)\ny_pred[:, 14] = (y_pred[:, 14] > 0.4).astype(int)\ny_pred[:, 15] = (y_pred[:, 15] > 0.2).astype(int)\ny_pred[:, 16] = (y_pred[:, 16] > 0.4).astype(int)\ny_pred[:, 17] = (y_pred[:, 17] > 0.4).astype(int)\ny_pred[:, 18] = (y_pred[:, 18] > 0.4).astype(int)\ny_pred[:, 19] = (y_pred[:, 19] > 0.4).astype(int)\ny_pred[:, 20] = (y_pred[:, 20] > 0.2).astype(int)\ny_pred[:, 21] = (y_pred[:, 21] > 0.4).astype(int)\ny_pred[:, 22] = (y_pred[:, 22] > 0.4).astype(int)\ny_pred[:, 23] = (y_pred[:, 23] > 0.4).astype(int)\ny_pred[:, 24] = (y_pred[:, 24] > 0.4).astype(int)\ny_pred[:, 25] = (y_pred[:, 25] > 0.4).astype(int)\ny_pred[:, 26] = (y_pred[:, 26] > 0.4).astype(int)\ny_pred[:, 27] = (y_pred[:, 27] > 0.2).astype(int)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e16aa069c468abde3bbb8d2ab577f919c9100660"
      },
      "cell_type": "code",
      "source": "y_sub = []\nfor label_set in y_pred:\n    index = 0\n    l = \"\"\n    for label in label_set:\n        if label == 1:\n            l += str(index)\n            l += \" \"\n            index += 1\n        else:\n            index += 1\n    y_sub.append(l[0:-1])\n    \nsubmission = pd.DataFrame({\"Predicted\":y_sub}, index=ids_test)\nsubmission.to_csv(\"submission.csv\", index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f002b43cfe6ce70ca976f947bb586a55997b9895"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}